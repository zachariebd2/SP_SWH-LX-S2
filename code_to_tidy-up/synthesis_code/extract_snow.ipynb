{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ad3ee4b-85dd-4cb4-a85e-41ffddbe72f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import errno\n",
    "import re\n",
    "import glob\n",
    "import csv\n",
    "import os.path as op\n",
    "import json\n",
    "import math\n",
    "from datetime import datetime, timedelta, date\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from osgeo import osr, ogr, gdal\n",
    "from osgeo.gdalnumeric import *\n",
    "from osgeo.gdalconst import *\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "import matplotlib.gridspec as pltg\n",
    "import seaborn as sn\n",
    "from matplotlib.colors import LogNorm\n",
    "import calendar\n",
    "import pyproj\n",
    "from pyproj import Proj, transform\n",
    "import warnings\n",
    "import rasterio\n",
    "\n",
    "import pickle\n",
    "from rasterio.warp import calculate_default_transform , reproject, Resampling \n",
    "from rasterio.mask import mask\n",
    "from rasterio.merge import merge\n",
    "from shapely.geometry import mapping, shape\n",
    "import statsmodels.api as sm\n",
    "import statsmodels\n",
    "import scipy.stats as st\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import geopandas as gpd\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13f4f7dc-b92d-477f-a349-9f3b15d8aa9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getDateFromStr(N):\n",
    "    sepList = [\"\",\"-\",\"_\",\"/\"]\n",
    "    datev = ''\n",
    "    for s in sepList :\n",
    "        found = re.search('\\d{4}'+ s +'\\d{2}'+ s +'\\d{2}', N)\n",
    "        if found != None :\n",
    "            datev = datetime.strptime(found.group(0), '%Y'+ s +'%m'+ s +'%d').date()\n",
    "            break\n",
    "    return datev\n",
    "\n",
    "def getTimeFromStr(N,):\n",
    "    sepList = [\"\",\"-\",\"_\"]\n",
    "    HHMMSS = ''\n",
    "    for s in sepList :\n",
    "        found = re.search('-'+'\\d{2}'+ s +'\\d{2}'+ s +'\\d{2}'+'-', N)\n",
    "        if found != None :\n",
    "            HHMMSS = datetime.strptime(found.group(0), '-'+'%H'+ s +'%M'+ s +'%S'+'-').time()\n",
    "            break\n",
    "    return HHMMSS\n",
    "\n",
    "def reproject(inEPSG,outEPSG,x1,y1):\n",
    "    \n",
    "    inProj = Proj(init='EPSG:' + inEPSG)\n",
    "    outProj = Proj(init='EPSG:'+ outEPSG)\n",
    "    x2,y2 = transform(inProj,outProj,x1,y1)\n",
    "    \n",
    "    return x2, y2\n",
    "\n",
    "def getCoords(G):\n",
    "    \n",
    "    \n",
    "    GT = G.GetGeoTransform()\n",
    "    minx = GT[0]\n",
    "    maxy = GT[3]\n",
    "    maxx = minx + GT[1] * G.RasterXSize\n",
    "    miny = maxy + GT[5] * G.RasterYSize\n",
    "    \n",
    "    return minx, maxy, maxx, miny\n",
    "\n",
    "def mkdir_p(dos):\n",
    "    try:\n",
    "        os.makedirs(dos)\n",
    "    except OSError as exc:  # Python >2.5\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(dos):\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "            \n",
    "def getTileFromStr(N):\n",
    "\n",
    "    tile = ''\n",
    "    found = re.search('\\d{2}' +'[A-Z]{3}', N)\n",
    "    if found != None : tile = found.group(0)\n",
    "    return tile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa667e54-3a95-4f8f-95ec-0de1002b0cb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "S2_tiles={\n",
    "    \"PYR\":\n",
    "    {\n",
    "        \"30TXN\":{'EPSG':'32630','MINX':600000,'MINY':4690200,'MAXX':709800,'MAXY':4800000},\n",
    "        '30TYN':{'EPSG':'32630','MINX':699960,'MINY':4690200,'MAXX':809760,'MAXY':4800000},\n",
    "        '31TCH':{'EPSG':'32631','MINX':300000,'MINY':4690200,'MAXX':409800,'MAXY':4800000},\n",
    "        '31TDH':{'EPSG':'32631','MINX':399960,'MINY':4690200,'MAXX':509760,'MAXY':4800000}\n",
    "    },\n",
    "    \"ALP\":\n",
    "    {\n",
    "        \"31TGJ\":{'EPSG':'32631','MINX':699960,'MINY':4790220,'MAXX':809760,'MAXY':4900020},\n",
    "        '31TGK':{'EPSG':'32631','MINX':699960,'MINY':4890240,'MAXX':809760,'MAXY':5000040},\n",
    "        '31TGL':{'EPSG':'32631','MINX':699960,'MINY':4990200,'MAXX':809760,'MAXY':5100000},\n",
    "        '31TGM':{'EPSG':'32631','MINX':699960,'MINY':5090220,'MAXX':809760,'MAXY':5200020},\n",
    "        \"32TLP\":{'EPSG':'32632','MINX':300000,'MINY':4790220,'MAXX':409800,'MAXY':4900020},\n",
    "        '32TLQ':{'EPSG':'32632','MINX':300000,'MINY':4890240,'MAXX':409800,'MAXY':5000040},\n",
    "        '32TLR':{'EPSG':'32632','MINX':300000,'MINY':4990200,'MAXX':409800,'MAXY':5100000},\n",
    "        '32TLS':{'EPSG':'32632','MINX':300000,'MINY':5090220,'MAXX':409800,'MAXY':5200020}\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "epsg_list={\n",
    "    \"30TXN\":{'EPSG':'32630'},\n",
    "    '30TYN':{'EPSG':'32630'},\n",
    "    '31TCH':{'EPSG':'32631'},\n",
    "    '31TDH':{'EPSG':'32631'},\n",
    "    \"31TGJ\":{'EPSG':'32631'},\n",
    "    '31TGK':{'EPSG':'32631'},\n",
    "    '31TGL':{'EPSG':'32631'},\n",
    "    '31TGM':{'EPSG':'32631'},\n",
    "    \"32TLP\":{'EPSG':'32632'},\n",
    "    '32TLQ':{'EPSG':'32632'},\n",
    "    '32TLR':{'EPSG':'32632'},\n",
    "    '32TLS':{'EPSG':'32632'}\n",
    "}\n",
    "\n",
    "\n",
    "S2_4326_tiles={\n",
    "    \"PYR\":\n",
    "    {\n",
    "        \"30TXN\":{'EPSG':'32630','MINX':reproject('32630','4326',600000,4690200)[0],'MINY':reproject('32630','4326',600000,4690200)[1],'MAXX':reproject('32630','4326',709800,4800000)[0],'MAXY':reproject('32630','4326',709800,4800000)[1]\n",
    "                },\n",
    "        '30TYN':{'EPSG':'32630','MINX':reproject('32630','4326',699960,4690200)[0],'MINY':reproject('32630','4326',699960,4690200)[1],'MAXX':reproject('32630','4326',809760,4800000)[0],'MAXY':reproject('32630','4326',809760,4800000)[1]\n",
    "                },\n",
    "        '31TCH':{'EPSG':'32631','MINX':reproject('32631','4326',300000,4690200)[0],'MINY':reproject('32631','4326',300000,4690200)[1],'MAXX':reproject('32631','4326',409800,4800000)[0],'MAXY':reproject('32631','4326',409800,4800000)[1]\n",
    "                },\n",
    "        '31TDH':{'EPSG':'32631','MINX':reproject('32631','4326',399960,4690200)[0],'MINY':reproject('32631','4326',399960,4690200)[1],'MAXX':reproject('32631','4326',509760,4800000)[0],'MAXY':reproject('32631','4326',509760,4800000)[1]\n",
    "                }\n",
    "    },\n",
    "    \"ALP\":\n",
    "    {\n",
    "        \"31TGJ\":{'EPSG':'32631','MINX':reproject('32631','4326',699960,4790220)[0],'MINY':reproject('32631','4326',699960,4790220)[1],'MAXX':reproject('32631','4326',809760,4900020)[0],'MAXY':reproject('32631','4326',809760,4900020)[1]\n",
    "                },\n",
    "        '31TGK':{'EPSG':'32631','MINX':reproject('32631','4326',699960,4890240)[0],'MINY':reproject('32631','4326',699960,4890240)[1],'MAXX':reproject('32631','4326',809760,5000040)[0],'MAXY':reproject('32631','4326',809760,5000040)[1]\n",
    "                },\n",
    "        '31TGL':{'EPSG':'32631','MINX':reproject('32631','4326',699960,4990200)[0],'MINY':reproject('32631','4326',699960,4990200)[1],'MAXX':reproject('32631','4326',809760,5100000)[0],'MAXY':reproject('32631','4326',809760,5100000)[1]\n",
    "                },\n",
    "        '31TGM':{'EPSG':'32631','MINX':reproject('32631','4326',699960,5090220)[0],'MINY':reproject('32631','4326',699960,5090220)[1],'MAXX':reproject('32631','4326',809760,5200020)[0],'MAXY':reproject('32631','4326',809760,5200020)[1]\n",
    "                },\n",
    "        \"32TLP\":{'EPSG':'32632','MINX':reproject('32632','4326',300000,4790220)[0],'MINY':reproject('32632','4326',300000,4790220)[1],'MAXX':reproject('32632','4326',409800,4900020)[0],'MAXY':reproject('32632','4326',409800,4900020)[1]\n",
    "                },\n",
    "        '32TLQ':{'EPSG':'32632','MINX':reproject('32632','4326',300000,4890240)[0],'MINY':reproject('32632','4326',300000,4890240)[1],'MAXX':reproject('32632','4326',409800,5000040)[0],'MAXY':reproject('32632','4326',409800,5000040)[1]\n",
    "                },\n",
    "        '32TLR':{'EPSG':'32632','MINX':reproject('32632','4326',300000,4990200)[0],'MINY':reproject('32632','4326',300000,4990200)[1],'MAXX':reproject('32632','4326',409800,5100000)[0],'MAXY':reproject('32632','4326',409800,5100000)[1]\n",
    "                },\n",
    "        '32TLS':{'EPSG':'32632','MINX':reproject('32632','4326',300000,5090220)[0],'MINY':reproject('32632','4326',300000,5090220)[1],'MAXX':reproject('32632','4326',409800,5200020)[0],'MAXY':reproject('32632','4326',409800,5200020)[1]\n",
    "                }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "LANDSAT_wrs={\n",
    "    \"ALP\":\n",
    "    {\n",
    "        \"195029\":[\"31TGJ\",'31TGK','31TGL',\"32TLP\",'32TLQ','32TLR'],\n",
    "        \"195028\":['31TGL','31TGM','32TLQ','32TLR','32TLS'],\n",
    "        \"196029\":[\"31TGJ\",'31TGK','31TGL','32TLQ','32TLR'],\n",
    "        \"196028\":['31TGK','31TGL','31TGM','32TLQ','32TLR','32TLS'],\n",
    "        \"194029\":[\"32TLP\",'32TLQ','32TLR']\n",
    "    },\n",
    "    \"PYR\":\n",
    "    {\n",
    "        \"200030\":[\"30TXN\",'30TYN'],\n",
    "        \"199030\":[\"30TXN\",'30TYN','31TCH'],\n",
    "        \"198031\":['31TCH','31TDH'],\n",
    "        \"198030\":['31TCH','31TDH'],\n",
    "        \"197031\":['31TDH']\n",
    "    }\n",
    "}\n",
    "\n",
    "LANDSAT_tiles={\n",
    "    \"ALP\":\n",
    "    {\n",
    "        \"31TGJ\":[\"195029\",\"196029\"],\n",
    "        '31TGK':[\"195029\",\"196029\",\"196028\"],\n",
    "        '31TGL':[\"195029\",\"195028\",\"196029\",\"196028\"],\n",
    "        '31TGM':[\"195028\",\"196028\"],\n",
    "        \"32TLP\":[\"194029\",\"195029\"],\n",
    "        '32TLQ':[\"194029\",\"195029\",\"195028\",\"196029\",\"196028\"],\n",
    "        '32TLR':[\"194029\",\"195029\",\"195028\",\"196029\",\"196028\"],\n",
    "        '32TLS':[\"195028\",\"196028\"]\n",
    "    },\n",
    "    \"PYR\":\n",
    "    {\n",
    "        \"30TXN\":[\"200030\",\"199030\"],\n",
    "        '30TYN':[\"200030\",\"199030\"],\n",
    "        '31TCH':[\"199030\",\"198031\",\"198030\"],\n",
    "        '31TDH':[\"198031\",\"198030\",\"197031\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "SPOT_tile={\n",
    "    \"ALP\":\n",
    "    {\"KMIN\":46,\n",
    "     \"KMAX\":55,\n",
    "     \"JMIN\":254,\n",
    "     \"JMAX\":263\n",
    "    },\n",
    "    \"PYR\":\n",
    "    {\"KMIN\":35,\n",
    "     \"KMAX\":48,\n",
    "     \"JMIN\":262,\n",
    "     \"JMAX\":265\n",
    "    }\n",
    "}\n",
    "\n",
    "SAFRAN_massifs={\n",
    "    \"ALP\":\n",
    "    {\"Chablais\",'Aravis','Mont-Blanc',\"Haute-Tarentaise\",\"Haute-Maurienne\",\n",
    "     \"Beaufortain\", \"Vanoise\",\"Maurienne\",\"Thabor\",\"Chartreuse\",\n",
    "     \"Bauges\",\"Oisans\",\"Grandes-Rousses\",\"Belledonne\",\"Vercors\",\n",
    "     \"Devoluy\",\"Champsaur\",\"Pelvoux\",\"Queyras\",\"Embrunnais Parpaillon\",\n",
    "     \"Ubaye\",\"Haut-Var Haut-Verdon\",\"Mercantour\"\n",
    "    },\n",
    "    \"PYR\":\n",
    "    {\"Pays-Basque\",\"Aspe Ossau\",\"Navarra\",\"Jacetiana\",\"Gallego\",\n",
    "     \"Haute-Bigorre\",\"Aure Louron\",\"Luchonnais\",\"Sobrarbe\",\"Esera\",\n",
    "     \"Couserans\",\"Aran\",\"Ribagorcana\",\"Pallaresa\",\"Haute-Ariege\",\n",
    "     \"Andorre\",\"Perafita\",\"Orlu St-Barthelemy\",\"Capcir Puymorens\",\"Cadi Moixero\",\n",
    "     'Ter-Freser','Cerdagne Canigou'\n",
    "    }\n",
    "}\n",
    "\n",
    "SAFRAN_tiles={\n",
    "    \"ALP\":\n",
    "    {\"31TGM\":[\"Chablais\",'Aravis','Mont-Blanc'],\n",
    "     \"32TLS\":[\"Chablais\",'Aravis','Mont-Blanc'],\n",
    "     \"32TLR\":[\"Chablais\",\"Mont-Blanc\",\"Haute-Tarentaise\",\n",
    "              \"Haute-Maurienne\",\"Beaufortain\",\"Aravis\",\n",
    "              \"Vanoise\",\"Maurienne\",\"Thabor\"],\n",
    "     \"31TGL\":[\"Mont-Blanc\",\"Chablais\",\"Aravis\",\"Beaufortain\",\n",
    "              \"Chartreuse\",\"Haute-Maurienne\",\"Vanoise\",\n",
    "              \"Maurienne\",\"Haute-Tarentaise\",\"Bauges\",\"Oisans\",\n",
    "              \"Grandes-Rousses\",\"Belledonne\",\"Thabor\",\"Vercors\"],\n",
    "     \"31TGK\":[\"Vercors\",\"Oisans\",\"Belledonne\",\"Grandes-Rousses\",\n",
    "              \"Devoluy\",\"Thabor\",\"Champsaur\",\"Pelvoux\",\"Queyras\",\n",
    "              \"Embrunnais Parpaillon\",\"Ubaye\",\"Haut-Var Haut-Verdon\",\n",
    "              \"Mercantour\"],\n",
    "     \"32TLQ\":[\"Queyras\",\"Thabor\",\"Pelvoux\",\"Embrunnais Parpaillon\",\n",
    "              \"Ubaye\",\"Haut-Var Haut-Verdon\",\"Mercantour\"],\n",
    "     \"32TLP\":[\"Haut-Var Haut-Verdon\",\"Mercantour\"],\n",
    "     \"31TGJ\":[\"Haut-Var Haut-Verdon\"]\n",
    "     \n",
    "    },\n",
    "    \"PYR\":\n",
    "    {\"30TXN\":[\"Pays-Basque\",\"Aspe Ossau\",\"Navarra\",\"Jacetiana\"],\n",
    "     \"30TYN\":[\"Aspe Ossau\",\"Jacetiana\",\"Haute-Bigorre\",\"Aure Louron\",\n",
    "              \"Luchonnais\",\"Gallego\",\"Sobrarbe\",\"Esera\",\n",
    "             \"Couserans\",\"Aran\",\"Ribagorcana\"],\n",
    "     \"31TCH\":[\"Luchonnais\",\"Esera\",\"Couserans\",\"Haute-Ariege\",\"Andorre\",\n",
    "              \"Aran\",\"Ribagorcana\",\"Pallaresa\",\"Perafita\",\"Orlu St-Barthelemy\",\n",
    "              \"Capcir Puymorens\",\"Cadi Moixero\"],\n",
    "     \"31TDH\":[\"Orlu St-Barthelemy\",\"Capcir Puymorens\",\"Cerdagne Canigou\",\n",
    "              \"Ter-Freser\",\"Cadi Moixero\",\"Perafita\",\"Haute-Ariege\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "SAFRAN_wrs={\n",
    "    \"ALP\":\n",
    "    {\n",
    "        \"195029\":[\"Haut-Var Haut-Verdon\",'Mercantour',\n",
    "                  'Ubaye',\"Embrunnais Parpaillon\",'Queyras',\n",
    "                  'Pelvoux','Champsaur','Oisans','Devoluy','Oisans',\n",
    "                  'Grandes-Rousses','Belledonne','Maurienne','Thabor',\n",
    "                  'Haute-Maurienne','Vanoise','Chartreuse','Bauges','Beaufortain','Haute-Tarentaise'],\n",
    "        \"196029\":[\"Haut-Var Haut-Verdon\",'Mercantour',\n",
    "                  'Ubaye',\"Embrunnais Parpaillon\",'Queyras',\n",
    "                  'Pelvoux','Champsaur','Oisans','Devoluy','Oisans',\n",
    "                  'Grandes-Rousses','Belledonne','Maurienne','Thabor',\n",
    "                  'Haute-Maurienne','Vanoise','Chartreuse','Vercors'],\n",
    "        \"195028\":['Chablais','Mont-Blanc','Aravis','Beaufortain',\n",
    "                  'Haute-Tarentaise','Bauges','Vanoise','Haute-Maurienne',\n",
    "                  'Maurienne','Belledonne','Chartreuse'],\n",
    "        \"196028\":['Chablais','Mont-Blanc','Aravis','Beaufortain',\n",
    "                  'Haute-Tarentaise','Bauges','Vanoise','Haute-Maurienne',\n",
    "                  'Maurienne','Belledonne','Chartreuse','Vercors','Grandes-Rousses','Thabor'],\n",
    "        \"194029\":[\"Haute-Maurienne\",'Queyras','Mercantour','Ubaye','Haut-Var Haut-Verdon']\n",
    "    },\n",
    "    \"PYR\":\n",
    "    {\n",
    "        \"200030\":[\"Pays-Basque\",\"Aspe Ossau\",\"Navarra\",\"Jacetiana\",\"Gallego\",\"Haute-Bigorre\"],\n",
    "        \"199030\":[\"Pays-Basque\",\"Aspe Ossau\",\"Navarra\",\"Jacetiana\",\"Gallego\",\"Haute-Bigorre\",\"Aure Louron\",\n",
    "                  \"Luchonnais\",\"Sobrarbe\",\"Esera\",\"Couserans\",\"Aran\",\"Ribagorcana\",\"Pallaresa\"],\n",
    "        \"198031\":[\"Haute-Ariege\",\"Andorre\",\"Aran\",\"Ribagorcana\",\"Pallaresa\",\"Perafita\",\"Orlu St-Barthelemy\",\n",
    "              \"Capcir Puymorens\",\"Cadi Moixero\",'Ter-Freser','Cerdagne Canigou'],\n",
    "        \"198030\":[\"Haute-Ariege\",\"Andorre\",\"Aran\",\"Ribagorcana\",\"Pallaresa\",\"Perafita\",\"Orlu St-Barthelemy\",\n",
    "              \"Capcir Puymorens\",\"Cadi Moixero\",'Ter-Freser','Cerdagne Canigou','Couserans','Orlu St-Barthelemy'],\n",
    "        \"197031\":[\"Orlu St-Barthelemy\",\"Capcir Puymorens\",\"Cerdagne Canigou\",\n",
    "              \"Ter-Freser\",\"Cadi Moixero\",\"Perafita\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2effd602-4b4e-4533-b7d1-9321a498be40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract swh snow maps from thabor\n",
    "\n",
    "SWH_path = \"/home/ad/barrouz/zacharie/TIMESERIES_PROJECT/SWH_INFERENCE/TCD-BLUE_AVG-1200\"\n",
    "out_dir = \"/home/ad/barrouz/zacharie/TIMESERIES_PROJECT/TOP/THABOR/SNOW/SWH\"\n",
    "shp_path = \"/home/ad/barrouz/zacharie/TIMESERIES_PROJECT/TOP/THABOR/SHP/THABOR.mask.shp\"\n",
    "tmp_dir = \"/home/ad/barrouz/zacharie/TIMESERIES_PROJECT/TOP/TMP\"\n",
    "shapefile = gpd.read_file(shp_path)\n",
    "lambert_epsg = \"2154\"\n",
    "safran_lambert = shapefile.to_crs({'init': f\"epsg:{lambert_epsg}\"})\n",
    "\n",
    "   \n",
    "skip=0\n",
    "\n",
    "\n",
    "for tile in ['31TGL']:\n",
    "    list_swh = glob.glob(os.path.join(SWH_path,f'ALP/*/*/*/*/*/{tile}/*/*FSCTOC.tif'))\n",
    "    already_done = glob.glob(os.path.join(out_dir,f'*{tile}*'))\n",
    "    nb_swh = len(list_swh)\n",
    "    nodata=0\n",
    "    for i,swh in enumerate(list_swh):\n",
    "        if out_dir+f\"/THABOR_\"+os.path.basename(swh) in already_done : \n",
    "            skip+=1\n",
    "            print(f\"{tile} {int((i+1)/nb_swh*100)}% skipped={skip}\",end=\"                                                                          \\r\")\n",
    "            continue\n",
    "        print(f\"{tile} {int((i+1)/nb_swh*100)}% skipped={skip}\",end=\"                                                                          \\r\")\n",
    "        \n",
    "\n",
    "        tmp_path = tmp_dir+f\"/swh_{i}_tmp.tif\"\n",
    "        lambert_geoms = [mapping((safran_lambert.geometry.values)[0])]\n",
    "        bounds = safran_lambert.geometry.total_bounds\n",
    "\n",
    "        tmp = gdal.Warp(tmp_path,swh,format=\"GTiff\",\n",
    "                        outputBounds= bounds,xRes=20,yRes=20,\n",
    "                        dstSRS=\"EPSG:\"+lambert_epsg,resampleAlg=\"near\",\n",
    "                        srcNodata=255,dstNodata=255)\n",
    "        tmp_array = tmp.GetRasterBand(1).ReadAsArray()\n",
    "        if np.all(tmp_array == 255): \n",
    "            os.system(\"rm \"+tmp_path)\n",
    "            continue\n",
    "        else:\n",
    "            with rasterio.open(tmp_path,'r') as src:\n",
    "                out_image, out_transform = mask(src, lambert_geoms,nodata=255)\n",
    "                out_meta = src.meta\n",
    "                out_meta.update({\"driver\": \"GTiff\",\n",
    "                \"height\": out_image.shape[1],\n",
    "                \"width\": out_image.shape[2],\n",
    "                \"transform\": out_transform})\n",
    "            if np.all(out_image[0] == 255):\n",
    "                os.system(\"rm \"+tmp_path)\n",
    "                continue\n",
    "            else:\n",
    "                mkdir_p(out_dir)\n",
    "                out=out_dir+f\"/THABOR_\"+os.path.basename(swh)\n",
    "                with rasterio.open(out, \"w\", **out_meta,compress='deflate') as dest:\n",
    "                    dest.write(out_image)\n",
    "                os.system(\"rm \"+tmp_path)\n",
    "                \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24daf85d-369c-4e8d-a67d-9be7de70bca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract dlr snow maps from thabor\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import mapping, shape\n",
    "from rasterio.mask import mask\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from osgeo import osr, ogr, gdal\n",
    "from osgeo.gdalnumeric import *\n",
    "from osgeo.gdalconst import *\n",
    "\n",
    "DLR_path = \"/home/ad/barrouz/zacharie/TIMESERIES_PROJECT/LANDSAT_QA_DLR\"\n",
    "out_dir = \"/home/ad/barrouz/zacharie/TIMESERIES_PROJECT/MISC/STCHRISTOPHE/DLR\"\n",
    "shp_path = \"/home/ad/barrouz/zacharie/TIMESERIES_PROJECT/MISC/VeneonStChristophe.kml\"\n",
    "tmp_dir = \"/home/ad/barrouz/zacharie/TIMESERIES_PROJECT/MISC/STCHRISTOPHE/TMP\"\n",
    "shapefile = gpd.read_file(shp_path,driver='LIBKML')\n",
    "lambert_epsg = \"4326\"\n",
    "safran_lambert = shapefile.to_crs({'init': f\"epsg:{lambert_epsg}\"})\n",
    "lambert_geoms = [mapping((safran_lambert.geometry.values)[0])]\n",
    "   \n",
    "\n",
    "\n",
    "for mtn in ['ALP']:\n",
    "    for wrs in [\"196029\",\"195029\"]:\n",
    "        list_dlr = glob.glob(os.path.join(DLR_path,f'{mtn}_LIS/*{wrs}/*FSCTOC.tif'))\n",
    "        print(list_dlr)\n",
    "        nb_dlr = len(list_dlr)\n",
    "        nodata=0\n",
    "        for i,dlr in enumerate(list_dlr):\n",
    "            print(dlr)\n",
    "            print(f\"{wrs} {int((i+1)/nb_dlr*100)}% \",end=\"                                                                          \\r\")\n",
    "\n",
    "            tmp_path = tmp_dir+f\"/dlr_{i}_tmp.tif\"\n",
    "            \n",
    "            bounds = safran_lambert.geometry.total_bounds\n",
    "            print(bounds)\n",
    "            tmp = gdal.Warp(tmp_path,dlr,format=\"GTiff\",xRes=20,yRes=20,\n",
    "                            dstSRS=\"EPSG:\"+lambert_epsg,resampleAlg=\"near\",\n",
    "                            srcNodata=255,dstNodata=255)\n",
    "            print(tmp)\n",
    "            tmp_array = tmp.GetRasterBand(1).ReadAsArray()\n",
    "            if np.all(tmp_array == 255): \n",
    "                os.system(\"rm \"+tmp_path)\n",
    "                continue\n",
    "            else:\n",
    "                with rasterio.open(tmp_path,'r') as src:\n",
    "                    out_image, out_transform = mask(src, lambert_geoms,nodata=255)\n",
    "                    out_meta = src.meta\n",
    "                    out_meta.update({\"driver\": \"GTiff\",\n",
    "                    \"height\": out_image.shape[1],\n",
    "                    \"width\": out_image.shape[2],\n",
    "                    \"transform\": out_transform})\n",
    "                if np.all(out_image[0] == 255):\n",
    "                    os.system(\"rm \"+tmp_path)\n",
    "                    continue\n",
    "                else:\n",
    "                    mkdir_p(out_dir)\n",
    "                    out=out_dir+f\"/STCHRISTOPHE_\"+os.path.basename(dlr)\n",
    "                    with rasterio.open(out, \"w\", **out_meta,compress='deflate') as dest:\n",
    "                        dest.write(out_image)\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9460c987-6edf-43b3-b572-35c076687338",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gpd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m shp_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/ad/barrouz/zacharie/TIMESERIES_PROJECT/SAFRAN/massifs_WGS84.shp\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m tmp_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/ad/barrouz/zacharie/TIMESERIES_PROJECT/TOP/TMP\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m shapefile \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_file(shp_path)\n\u001b[1;32m      8\u001b[0m lambert_epsg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2154\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m safran_lambert \u001b[38;5;241m=\u001b[39m shapefile\u001b[38;5;241m.\u001b[39mto_crs({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepsg:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlambert_epsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gpd' is not defined"
     ]
    }
   ],
   "source": [
    "#extract swh snow maps from safran shapefile\n",
    "\n",
    "SWH_path = \"/home/ad/barrouz/zacharie/TIMESERIES_PROJECT/SWH_INFERENCE/TCD-BLUE_AVG-1200\"\n",
    "out_dir = \"/home/ad/barrouz/zacharie/TIMESERIES_PROJECT/TOP/SAFRAN\"\n",
    "shp_path = \"/home/ad/barrouz/zacharie/TIMESERIES_PROJECT/SAFRAN/massifs_WGS84.shp\"\n",
    "tmp_dir = \"/home/ad/barrouz/zacharie/TIMESERIES_PROJECT/TOP/TMP\"\n",
    "shapefile = gpd.read_file(shp_path)\n",
    "lambert_epsg = \"2154\"\n",
    "safran_lambert = shapefile.to_crs({'init': f\"epsg:{lambert_epsg}\"})\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "for mtn in SAFRAN_tiles:\n",
    "    for tile in SAFRAN_tiles[mtn]:\n",
    "        if tile not in [\"31TDH\"]: continue\n",
    "        skip=0\n",
    "        data=0\n",
    "        list_swh = glob.glob(os.path.join(SWH_path,f'{mtn}/*/*/*/*/*/{tile}/*/*FSCTOC.tif'))\n",
    "        nb_swh = len(list_swh)\n",
    "        nodata=0\n",
    "        for i,swh in enumerate(list_swh):\n",
    "            print(f\"{tile} {int((i+1)/nb_swh*100)}% all = {data} skipped={skip} nodata={nodata}\",end=\"                              \\r\")\n",
    "            \n",
    "\n",
    "\n",
    "            for j,safran in enumerate(SAFRAN_tiles[mtn][tile]):\n",
    "                data+=1\n",
    "                tmp_path = tmp_dir+f\"/swh_{i}_{j}_tmp.tif\"\n",
    "                name = safran_lambert.loc[safran_lambert['title'] == safran, 'title_s'].values[0]\n",
    "                out_path = out_dir+f\"/{mtn}/{name}/SWH\"\n",
    "                already_done = glob.glob(os.path.join(out_path,f'{name}*{tile}*'))\n",
    "                if out_path+f\"/{name}_\"+os.path.basename(swh) in already_done : \n",
    "                    skip+=1\n",
    "                    print(f\"{tile} {int((i+1)/nb_swh*100)}% all = {data} skipped={skip} nodata={nodata}\",end=\"                              \\r\")\n",
    "                    continue\n",
    "                lambert_geoms = [mapping(((safran_lambert.query(f\"title == '{safran}'\")).geometry.values)[0])]\n",
    "                bounds = safran_lambert.loc[safran_lambert['title'] == safran, 'geometry'].total_bounds\n",
    "                \n",
    "                tmp = gdal.Warp(tmp_path,swh,format=\"GTiff\",\n",
    "                                outputBounds= bounds,xRes=20,yRes=20,\n",
    "                                dstSRS=\"EPSG:\"+lambert_epsg,resampleAlg=\"near\",\n",
    "                                srcNodata=255,dstNodata=255)\n",
    "                tmp_array = tmp.GetRasterBand(1).ReadAsArray()\n",
    "                if np.all(tmp_array == 255): \n",
    "                    os.system(\"rm \"+tmp_path)\n",
    "                    nodata+=1\n",
    "                    print(f\"{tile} {int((i+1)/nb_swh*100)}% all = {data} skipped={skip} nodata={nodata}\",end=\"                              \\r\")\n",
    "                    continue\n",
    "                else:\n",
    "                    with rasterio.open(tmp_path,'r') as src:\n",
    "                        out_image, out_transform = mask(src, lambert_geoms,nodata=255)\n",
    "                        out_meta = src.meta\n",
    "                        out_meta.update({\"driver\": \"GTiff\",\n",
    "                        \"height\": out_image.shape[1],\n",
    "                        \"width\": out_image.shape[2],\n",
    "                        \"transform\": out_transform})\n",
    "                    if np.all(out_image[0] == 255):\n",
    "                        os.system(\"rm \"+tmp_path)\n",
    "                        nodata+=1\n",
    "                        print(f\"{tile} {int((i+1)/nb_swh*100)}% all = {data} skipped={skip} nodata={nodata}\",end=\"                              \\r\")\n",
    "                        continue\n",
    "                    else:\n",
    "                        mkdir_p(out_path)\n",
    "                        out=out_path+f\"/{name}_\"+os.path.basename(swh)\n",
    "                        with rasterio.open(out, \"w\", **out_meta,compress='deflate') as dest:\n",
    "                            dest.write(out_image)\n",
    "                        os.system(\"rm \"+tmp_path)\n",
    "                \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f36f56e-e11a-4a4f-8af8-b1b7ddc5a979",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract dlr snow maps from safran shapefile\n",
    "\n",
    "DLR_path = \"/home/ad/barrouz/zacharie/TIMESERIES_PROJECT/LANDSAT_QA_DLR\"\n",
    "out_dir = \"/home/ad/barrouz/zacharie/TIMESERIES_PROJECT/TOP/SAFRAN\"\n",
    "shp_path = \"/home/ad/barrouz/zacharie/TIMESERIES_PROJECT/SAFRAN/massifs_WGS84.shp\"\n",
    "tmp_dir = \"/home/ad/barrouz/zacharie/TIMESERIES_PROJECT/TOP/TMP\"\n",
    "shapefile = gpd.read_file(shp_path)\n",
    "lambert_epsg = \"2154\"\n",
    "safran_lambert = shapefile.to_crs({'init': f\"epsg:{lambert_epsg}\"})\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "for mtn in [\"PYR\"]:\n",
    "    for wrs in [\"198030\",\"197031\"]:\n",
    "        list_dlr = glob.glob(os.path.join(DLR_path,f'{mtn}_LIS/*{wrs}/*FSCTOC.tif'))\n",
    "        nb_dlr = len(list_dlr)\n",
    "        data=0\n",
    "        nodata=0\n",
    "        for i,dlr in enumerate(list_dlr):\n",
    "            print(f\"{wrs} {int((i+1)/nb_dlr*100)}% all = {data} nodata={nodata}\",end=\"                                        \\r\")\n",
    "            for j,safran in enumerate(SAFRAN_wrs[mtn][wrs]):\n",
    "                data+=1\n",
    "                tmp_path = tmp_dir+f\"/dlr_{i}_{j}_tmp.tif\"\n",
    "                name = safran_lambert.loc[safran_lambert['title'] == safran, 'title_s'].values[0]\n",
    "                out_path = out_dir+f\"/{mtn}/{name}/DLR\"\n",
    "                lambert_geoms = [mapping(((safran_lambert.query(f\"title == '{safran}'\")).geometry.values)[0])]\n",
    "                bounds = safran_lambert.loc[safran_lambert['title'] == safran, 'geometry'].total_bounds\n",
    "                \n",
    "                tmp = gdal.Warp(tmp_path,dlr,format=\"GTiff\",\n",
    "                                outputBounds= bounds,xRes=20,yRes=20,\n",
    "                                dstSRS=\"EPSG:\"+lambert_epsg,resampleAlg=\"near\",\n",
    "                                srcNodata=255,dstNodata=255)\n",
    "                tmp_array = tmp.GetRasterBand(1).ReadAsArray()\n",
    "                if np.all(tmp_array == 255): \n",
    "                    os.system(\"rm \"+tmp_path)\n",
    "                    nodata+=1\n",
    "                    print(f\"{wrs} {int((i+1)/nb_dlr*100)}% all = {data} nodata={nodata}\",end=\"                                        \\r\")\n",
    "                    continue\n",
    "                else:\n",
    "                    with rasterio.open(tmp_path,'r') as src:\n",
    "                        out_image, out_transform = mask(src, lambert_geoms,nodata=255)\n",
    "                        out_meta = src.meta\n",
    "                        out_meta.update({\"driver\": \"GTiff\",\n",
    "                        \"height\": out_image.shape[1],\n",
    "                        \"width\": out_image.shape[2],\n",
    "                        \"transform\": out_transform})\n",
    "                    if np.all(out_image[0] == 255):\n",
    "                        os.system(\"rm \"+tmp_path)\n",
    "                        nodata += 1\n",
    "                        print(f\"{wrs} {int((i+1)/nb_dlr*100)}% all = {data} nodata={nodata}\",end=\"                                        \\r\")\n",
    "                        continue\n",
    "                    else:\n",
    "                        mkdir_p(out_path)\n",
    "                        out=out_path+f\"/{name}_\"+os.path.basename(dlr)\n",
    "                        with rasterio.open(out, \"w\", **out_meta,compress='deflate') as dest:\n",
    "                            dest.write(out_image)\n",
    "                            print(f\"{wrs} {int((i+1)/nb_dlr*100)}% all = {data} nodata={nodata}\",end=\"                                        \\r\")\n",
    "                \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aea143-462f-4e9c-940d-73e8f2b0e463",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALP 32TLQ SOD 58%                                \r"
     ]
    }
   ],
   "source": [
    "#extract synthesis maps from safran shapefile\n",
    "\n",
    "SWH_path = \"/home/ad/barrouz/zacharie/TIMESERIES_PROJECT/SYNTHESIS/LANDSAT_SWH/TCD-BLUE_AVG-1200\"\n",
    "out_dir = \"/home/ad/barrouz/zacharie/TIMESERIES_PROJECT/TOP/SYNTHESIS\"\n",
    "shp_path = \"/home/ad/barrouz/zacharie/TIMESERIES_PROJECT/SAFRAN/massifs_WGS84.shp\"\n",
    "tmp_dir = \"/home/ad/barrouz/zacharie/TIMESERIES_PROJECT/TOP/TMP\"\n",
    "shapefile = gpd.read_file(shp_path)\n",
    "lambert_epsg = \"2154\"\n",
    "safran_lambert = shapefile.to_crs({'init': f\"epsg:{lambert_epsg}\"})\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "for mtn in [\"PYR\",\"ALP\"]:\n",
    "    for tile in SAFRAN_tiles[mtn]:\n",
    "        for metric in [\"NOBS\",\"NSP\",\"SCD\",\"SMOD\",\"SOD\"]:\n",
    "\n",
    "            list_swh = glob.glob(os.path.join(SWH_path,f'{mtn}/{tile}/*/*{metric}*'))\n",
    "            nb_swh = len(list_swh)\n",
    "\n",
    "            for i,swh in enumerate(list_swh):\n",
    "                print(f\"{mtn} {tile} {metric} {int((i+1)/nb_swh*100)}%\",end=\"                              \\r\")\n",
    "\n",
    "                for j,safran in enumerate(SAFRAN_tiles[mtn][tile]):\n",
    "                    tmp_path = tmp_dir+f\"/swh_{i}_{j}_tmp.tif\"\n",
    "                    name = safran_lambert.loc[safran_lambert['title'] == safran, 'title_s'].values[0]\n",
    "                    out_path = out_dir+f\"/{mtn}/{name}/{metric}\"\n",
    "\n",
    "                    lambert_geoms = [mapping(((safran_lambert.query(f\"title == '{safran}'\")).geometry.values)[0])]\n",
    "                    bounds = safran_lambert.loc[safran_lambert['title'] == safran, 'geometry'].total_bounds\n",
    "\n",
    "                    tmp = gdal.Warp(tmp_path,swh,format=\"GTiff\",\n",
    "                                    outputBounds= bounds,xRes=20,yRes=20,\n",
    "                                    dstSRS=\"EPSG:\"+lambert_epsg,resampleAlg=\"near\",\n",
    "                                    srcNodata=400,dstNodata=400)\n",
    "                    tmp_array = tmp.GetRasterBand(1).ReadAsArray()\n",
    "                    if np.all(tmp_array == 400): \n",
    "                        os.system(\"rm \"+tmp_path)\n",
    "                        continue\n",
    "                    else:\n",
    "                        with rasterio.open(tmp_path,'r') as src:\n",
    "                            out_image, out_transform = mask(src, lambert_geoms,nodata=400)\n",
    "                            out_meta = src.meta\n",
    "                            out_meta.update({\"driver\": \"GTiff\",\n",
    "                            \"height\": out_image.shape[1],\n",
    "                            \"width\": out_image.shape[2],\n",
    "                            \"transform\": out_transform})\n",
    "                        if np.all(out_image[0] == 400):\n",
    "                            os.system(\"rm \"+tmp_path)\n",
    "                            continue\n",
    "                        else:\n",
    "                            mkdir_p(out_path)\n",
    "                            out=out_path+f\"/{name}_\"+os.path.basename(swh)\n",
    "                            with rasterio.open(out, \"w\", **out_meta,compress='deflate') as dest:\n",
    "                                dest.write(out_image)\n",
    "                            os.system(\"rm \"+tmp_path)\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19977b1d-6c04-4e52-9e86-0cab9c6883f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYR AuLou merge dates 100%                                        \r"
     ]
    }
   ],
   "source": [
    "#merge same date & same massif SWH rasters\n",
    "SWH_path = \"/home/ad/barrouz/zacharie/TIMESERIES_PROJECT/TOP/SAFRAN\"\n",
    "out_dir = \"/home/ad/barrouz/zacharie/TIMESERIES_PROJECT/TOP/MERGED\"\n",
    "\n",
    "for mtn in os.listdir(SWH_path):\n",
    "    for massif in os.listdir(os.path.join(SWH_path,mtn)):\n",
    "        if massif != \"AuLou\" : continue\n",
    "        out_path = os.path.join(out_dir,mtn,massif,\"SWH\")\n",
    "        mkdir_p(out_path)\n",
    "        #get list of products\n",
    "        swh_list = glob.glob(os.path.join(SWH_path,mtn,massif,\"SWH\",'*'))\n",
    "        #sort by dates\n",
    "        dict_dates={}\n",
    "        print(f\"{mtn} {massif} sort dates\",end=\"                                        \\r\")\n",
    "        for swh in swh_list:\n",
    "            date_swh = getDateFromStr(swh)\n",
    "            if date_swh not in dict_dates : dict_dates[date_swh] = []\n",
    "            dict_dates[date_swh].append(swh)\n",
    "        # merge by dates\n",
    "        len_dates = len(dict_dates)\n",
    "        for i,date_swh in enumerate(dict_dates):\n",
    "            to_merge = \" \".join(dict_dates[date_swh])\n",
    "            out = os.path.join(out_path,f\"{massif}_SWH_{date_swh.strftime('%Y%m%d')}_SNOW.tif\")\n",
    "            os.system(f\"gdal_merge.py -n 255 -a_nodata 255 -quiet -co COMPRESS=DEFLATE -o {out} {to_merge}\")\n",
    "            print(f\"{mtn} {massif} merge dates {int((i+1)/len_dates*100)}%\",end=\"                                        \\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad61de07-0892-499c-925c-353b86693a1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLR merge dates 100%                                                 \r"
     ]
    }
   ],
   "source": [
    "#merge same date & same massif SWH thabor\n",
    "SWH_path = \"/home/ad/barrouz/zacharie/TIMESERIES_PROJECT/TOP/THABOR/SNOW\"\n",
    "out_dir = \"/home/ad/barrouz/zacharie/TIMESERIES_PROJECT/TOP/THABOR_MERGED\"\n",
    "\n",
    "for sat in os.listdir(SWH_path):\n",
    "    out_path = os.path.join(out_dir,sat)\n",
    "    mkdir_p(out_path)\n",
    "    #get list of products\n",
    "    swh_list = glob.glob(os.path.join(SWH_path,sat,'*'))\n",
    "    #sort by dates\n",
    "    dict_dates={}\n",
    "    print(f\"{sat} sort dates\",end=\"                                        \\r\")\n",
    "    for swh in swh_list:\n",
    "        date_swh = getDateFromStr(swh)\n",
    "        if date_swh not in dict_dates : dict_dates[date_swh] = []\n",
    "        dict_dates[date_swh].append(swh)\n",
    "    # merge by dates\n",
    "    len_dates = len(dict_dates)\n",
    "    for i,date_swh in enumerate(dict_dates):\n",
    "        to_merge = \" \".join(dict_dates[date_swh])\n",
    "        out = os.path.join(out_path,f\"THABOR_{sat}_{date_swh.strftime('%Y%m%d')}_SNOW.tif\")\n",
    "        os.system(f\"gdal_merge.py -n 255 -a_nodata 255 -quiet -co COMPRESS=DEFLATE -o {out} {to_merge}\")\n",
    "        print(f\"{sat} merge dates {int((i+1)/len_dates*100)}%\",end=\"                                        \\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99486d2-f4fc-4440-91af-c58703d9ed81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#merge same date & same massif synthesis rasters\n",
    "SWH_path = \"/home/ad/barrouz/zacharie/TIMESERIES_PROJECT/TOP/SYNTHESIS\"\n",
    "out_dir = \"/home/ad/barrouz/zacharie/TIMESERIES_PROJECT/TOP/SYNTHESIS_MERGED\"\n",
    "\n",
    "for mtn in os.listdir(SWH_path):\n",
    "    for massif in os.listdir(os.path.join(SWH_path,mtn)):\n",
    "        for metric in os.listdir(os.path.join(SWH_path,mtn,massif)):\n",
    "            out_path = os.path.join(out_dir,mtn,massif,metric)\n",
    "            mkdir_p(out_path)\n",
    "            #get list of products\n",
    "            swh_list = glob.glob(os.path.join(SWH_path,mtn,massif,metric,'*'))\n",
    "            #sort by dates\n",
    "            dict_dates={}\n",
    "            print(f\"{mtn} {massif} sort dates\",end=\"                                        \\r\")\n",
    "            for swh in swh_list:\n",
    "                date_swh = getDateFromStr(swh)\n",
    "                if date_swh.year not in dict_dates : dict_dates[date_swh.year] = []\n",
    "                dict_dates[date_swh.year].append(swh)\n",
    "            # merge by dates\n",
    "            len_dates = len(dict_dates)\n",
    "            for i,date_swh in enumerate(dict_dates):\n",
    "                to_merge = \" \".join(dict_dates[date_swh])\n",
    "                out = os.path.join(out_path,f\"{massif}_SWH_{date_swh.strftime('%Y%m%d')}_SNOW.tif\")\n",
    "                os.system(f\"gdal_merge.py -n 400 -a_nodata 400 -quiet -co COMPRESS=DEFLATE -o {out} {to_merge}\")\n",
    "                print(f\"{mtn} {massif} merge dates {int((i+1)/len_dates*100)}%\",end=\"                                        \\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "901f0360-65eb-46fa-af80-0ba35d0e3fea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AspOs',\n",
       " 'Couse',\n",
       " 'Navar',\n",
       " 'Lucho',\n",
       " 'OrSBa',\n",
       " 'Jacet',\n",
       " 'Ribag',\n",
       " 'P-Bas',\n",
       " 'Aran',\n",
       " 'Palla',\n",
       " 'Andor',\n",
       " 'Galle',\n",
       " 'CerCa',\n",
       " 'Peraf',\n",
       " 'Sobra',\n",
       " 'CaPuy',\n",
       " 'H-Big',\n",
       " 'TerFr',\n",
       " 'Esera',\n",
       " 'H-Ari',\n",
       " 'CaMoi',\n",
       " 'AuLou']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.path.join(\"/home/ad/barrouz/zacharie/TIMESERIES_PROJECT/TOP/SAFRAN\",\"PYR\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27db5001-6ce8-4af8-85a6-e10cb03f74ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALP H-Tar merge dates 34%                                         \r"
     ]
    }
   ],
   "source": [
    "#merge same date & same massif DLR rasters\n",
    "SWH_path = \"/home/ad/barrouz/zacharie/TIMESERIES_PROJECT/TOP/SAFRAN\"\n",
    "out_dir = \"/home/ad/barrouz/zacharie/TIMESERIES_PROJECT/TOP/MERGED\"\n",
    "\n",
    "for mtn in os.listdir(SWH_path):\n",
    "    for massif in os.listdir(os.path.join(SWH_path,mtn)):\n",
    "        out_path = os.path.join(out_dir,mtn,massif,\"DLR\")\n",
    "        mkdir_p(out_path)\n",
    "        #get list of products\n",
    "        swh_list = glob.glob(os.path.join(SWH_path,mtn,massif,\"DLR\",'*'))\n",
    "        #sort by dates\n",
    "        dict_dates={}\n",
    "        print(f\"{mtn} {massif} sort dates\",end=\"                                        \\r\")\n",
    "        for swh in swh_list:\n",
    "            date_swh = getDateFromStr(swh)\n",
    "            if date_swh not in dict_dates : dict_dates[date_swh] = []\n",
    "            dict_dates[date_swh].append(swh)\n",
    "        # merge by dates\n",
    "        len_dates = len(dict_dates)\n",
    "        for i,date_swh in enumerate(dict_dates):\n",
    "            to_merge = \" \".join(dict_dates[date_swh])\n",
    "            out = os.path.join(out_path,f\"{massif}_DLR_{date_swh.strftime('%Y%m%d')}_SNOW.tif\")\n",
    "            os.system(f\"gdal_merge.py -n 255 -a_nodata 255 -quiet -co COMPRESS=DEFLATE -o {out} {to_merge}\")\n",
    "            print(f\"{mtn} {massif} merge dates {int((i+1)/len_dates*100)}%\",end=\"                                        \\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb970cb-e64b-4346-be4b-37eb05cca6e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
